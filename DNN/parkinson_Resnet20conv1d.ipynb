{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa544660",
   "metadata": {
    "papermill": {
     "duration": 0.007996,
     "end_time": "2023-06-08T09:56:27.246334",
     "exception": false,
     "start_time": "2023-06-08T09:56:27.238338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Copy from https://www.kaggle.com/code/mayukh18/pytorch-fog-end-to-end-baseline-lb-0-254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd5845e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-08T09:56:27.262975Z",
     "iopub.status.busy": "2023-06-08T09:56:27.262059Z",
     "iopub.status.idle": "2023-06-08T09:56:30.762764Z",
     "shell.execute_reply": "2023-06-08T09:56:30.761590Z"
    },
    "papermill": {
     "duration": 3.512239,
     "end_time": "2023-06-08T09:56:30.765713",
     "exception": false,
     "start_time": "2023-06-08T09:56:27.253474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env set ok ..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "print(\"Env set ok ..\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d68cf4bd",
   "metadata": {
    "papermill": {
     "duration": 0.006933,
     "end_time": "2023-06-08T09:56:30.779749",
     "exception": false,
     "start_time": "2023-06-08T09:56:30.772816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stratified Group K Fold\n",
    "\n",
    "It's mentioned in the data that the subjects are different in the train and test set and even different between the public/private splits of the test data. So we need to use Stratified Group K Fold. But since the positive instances in the sequences are very scarce, we need to pick up the best fold which will give us the best balance of the positive/negative instances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dc6d799",
   "metadata": {
    "papermill": {
     "duration": 0.007767,
     "end_time": "2023-06-08T09:56:30.794562",
     "exception": false,
     "start_time": "2023-06-08T09:56:30.786795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### tdcsfog preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb88e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:56:30.811699Z",
     "iopub.status.busy": "2023-06-08T09:56:30.809827Z",
     "iopub.status.idle": "2023-06-08T09:56:49.057825Z",
     "shell.execute_reply": "2023-06-08T09:56:49.055825Z"
    },
    "papermill": {
     "duration": 18.259043,
     "end_time": "2023-06-08T09:56:49.060628",
     "exception": false,
     "start_time": "2023-06-08T09:56:30.801585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 833/833 [00:18<00:00, 46.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 files have positive values in all 3 classes\n",
      "Fold = 0\n",
      "Length of Train = 672, Length of Valid = 161\n",
      "Train classes: 287,832, 1,462,652, 175,633\n",
      "Valid classes: 16,958, 216,130, 32,205\n",
      "Fold = 1\n",
      "Length of Train = 613, Length of Valid = 220\n",
      "Train classes: 51,748, 909,505, 65,242\n",
      "Valid classes: 253,042, 769,277, 142,596\n",
      "Fold = 2\n",
      "Length of Train = 703, Length of Valid = 130\n",
      "Train classes: 271,881, 1,332,746, 183,673\n",
      "Valid classes: 32,909, 346,036, 24,165\n",
      "Fold = 3\n",
      "Length of Train = 649, Length of Valid = 184\n",
      "Train classes: 303,710, 1,517,147, 205,196\n",
      "Valid classes: 1,080, 161,635, 2,642\n",
      "Fold = 4\n",
      "Length of Train = 695, Length of Valid = 138\n",
      "Train classes: 303,989, 1,493,078, 201,608\n",
      "Valid classes: 801, 185,704, 6,230\n",
      "Fold = 2\n",
      "Length of Train = 703, Length of Valid = 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of positive instances in each fold of our CV folds\n",
    "\n",
    "n1_sum = []\n",
    "n2_sum = []\n",
    "n3_sum = []\n",
    "count = []\n",
    "\n",
    "# Here I am using the metadata file available during training. Since the code \n",
    "# will run again during submission, if \n",
    "# I used the usual file from the competition folder, \n",
    "# it would have been updated with the test files too.\n",
    "metadata = pd.read_csv(\"/kaggle/input/copy-train-metadata/tdcsfog_metadata.csv\")\n",
    "\n",
    "for f in tqdm(metadata['Id']):\n",
    "    fpath = f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{f}.csv\"\n",
    "    df = pd.read_csv(fpath)\n",
    "    \n",
    "    n1_sum.append(np.sum(df['StartHesitation']))\n",
    "    n2_sum.append(np.sum(df['Turn']))\n",
    "    n3_sum.append(np.sum(df['Walking']))\n",
    "    count.append(len(df))\n",
    "    \n",
    "print(f\"32 files have positive values in all 3 classes\")\n",
    "\n",
    "metadata['n1_sum'] = n1_sum\n",
    "metadata['n2_sum'] = n2_sum\n",
    "metadata['n3_sum'] = n3_sum\n",
    "metadata['count'] = count\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n",
    "    print(f\"Fold = {i}\")\n",
    "    train_ids = metadata.loc[train_index, 'Id']\n",
    "    valid_ids = metadata.loc[valid_index, 'Id']\n",
    "    \n",
    "    print(f\"Length of Train = {len(train_index)}, Length of Valid = {len(valid_index)}\")\n",
    "    n1_sum = metadata.loc[train_index, 'n1_sum'].sum()\n",
    "    n2_sum = metadata.loc[train_index, 'n2_sum'].sum()\n",
    "    n3_sum = metadata.loc[train_index, 'n3_sum'].sum()\n",
    "    print(f\"Train classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n",
    "    \n",
    "    n1_sum = metadata.loc[valid_index, 'n1_sum'].sum()\n",
    "    n2_sum = metadata.loc[valid_index, 'n2_sum'].sum()\n",
    "    n3_sum = metadata.loc[valid_index, 'n3_sum'].sum()\n",
    "    print(f\"Valid classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n",
    "    \n",
    "# FOLD 2 is the most well balanced\n",
    "# The actual train-test split (based on Fold 2)\n",
    "\n",
    "metadata = pd.read_csv(\"/kaggle/input/copy-train-metadata/tdcsfog_metadata.csv\")\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n",
    "    if i != 2:\n",
    "        continue\n",
    "    print(f\"Fold = {i}\")\n",
    "    train_ids = metadata.loc[train_index, 'Id']\n",
    "    valid_ids = metadata.loc[valid_index, 'Id']\n",
    "    print(f\"Length of Train = {len(train_ids)}, Length of Valid = {len(valid_ids)}\")\n",
    "    \n",
    "    if i == 2:\n",
    "        break\n",
    "        \n",
    "train_fpaths_tdcs = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{_id}.csv\" for _id in train_ids]\n",
    "valid_fpaths_tdcs = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{_id}.csv\" for _id in valid_ids]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e14ea2b9",
   "metadata": {
    "papermill": {
     "duration": 0.018889,
     "end_time": "2023-06-08T09:56:49.098966",
     "exception": false,
     "start_time": "2023-06-08T09:56:49.080077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### defog preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87beeed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:56:49.135790Z",
     "iopub.status.busy": "2023-06-08T09:56:49.135401Z",
     "iopub.status.idle": "2023-06-08T09:57:12.991049Z",
     "shell.execute_reply": "2023-06-08T09:57:12.989919Z"
    },
    "papermill": {
     "duration": 23.879507,
     "end_time": "2023-06-08T09:57:12.996035",
     "exception": false,
     "start_time": "2023-06-08T09:56:49.116528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:23<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0\n",
      "Length of Train = 75, Length of Valid = 16\n",
      "Train classes: 500, 428,683, 37,609\n",
      "Valid classes: 0, 158,803, 60,910\n",
      "Fold = 1\n",
      "Length of Train = 65, Length of Valid = 26\n",
      "Train classes: 216, 490,429, 84,955\n",
      "Valid classes: 284, 97,057, 13,564\n",
      "Fold = 2\n",
      "Length of Train = 76, Length of Valid = 15\n",
      "Train classes: 410, 488,634, 87,986\n",
      "Valid classes: 90, 98,852, 10,533\n",
      "Fold = 3\n",
      "Length of Train = 70, Length of Valid = 21\n",
      "Train classes: 435, 424,494, 88,800\n",
      "Valid classes: 65, 162,992, 9,719\n",
      "Fold = 4\n",
      "Length of Train = 78, Length of Valid = 13\n",
      "Train classes: 439, 517,704, 94,726\n",
      "Valid classes: 61, 69,782, 3,793\n",
      "Fold = 1\n",
      "Length of Train = 65, Length of Valid = 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of positive instances in each fold of our CV folds\n",
    "\n",
    "n1_sum = []\n",
    "n2_sum = []\n",
    "n3_sum = []\n",
    "count = []\n",
    "\n",
    "# Here I am using the metadata file available during training. Since the code will run again during submission, if \n",
    "# I used the usual file from the competition folder, it would have been updated with the test files too.\n",
    "metadata = pd.read_csv(\"/kaggle/input/copy-train-metadata/defog_metadata.csv\")\n",
    "metadata['n1_sum'] = 0\n",
    "metadata['n2_sum'] = 0\n",
    "metadata['n3_sum'] = 0\n",
    "metadata['count'] = 0\n",
    "\n",
    "for f in tqdm(metadata['Id']):\n",
    "    fpath = f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/{f}.csv\"\n",
    "    if os.path.exists(fpath) == False:\n",
    "        continue\n",
    "        \n",
    "    df = pd.read_csv(fpath)\n",
    "    metadata.loc[metadata['Id'] == f, 'n1_sum'] = np.sum(df['StartHesitation'])\n",
    "    metadata.loc[metadata['Id'] == f, 'n2_sum'] = np.sum(df['Turn'])\n",
    "    metadata.loc[metadata['Id'] == f, 'n3_sum'] = np.sum(df['Walking'])\n",
    "    metadata.loc[metadata['Id'] == f, 'count'] = len(df)\n",
    "    \n",
    "metadata = metadata[metadata['count'] > 0].reset_index()\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n",
    "    print(f\"Fold = {i}\")\n",
    "    train_ids = metadata.loc[train_index, 'Id']\n",
    "    valid_ids = metadata.loc[valid_index, 'Id']\n",
    "    \n",
    "    print(f\"Length of Train = {len(train_index)}, Length of Valid = {len(valid_index)}\")\n",
    "    n1_sum = metadata.loc[train_index, 'n1_sum'].sum()\n",
    "    n2_sum = metadata.loc[train_index, 'n2_sum'].sum()\n",
    "    n3_sum = metadata.loc[train_index, 'n3_sum'].sum()\n",
    "    print(f\"Train classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n",
    "    \n",
    "    n1_sum = metadata.loc[valid_index, 'n1_sum'].sum()\n",
    "    n2_sum = metadata.loc[valid_index, 'n2_sum'].sum()\n",
    "    n3_sum = metadata.loc[valid_index, 'n3_sum'].sum()\n",
    "    print(f\"Valid classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n",
    "    \n",
    "# FOLD 2 is the most well balanced\n",
    "# The actual train-test split (based on Fold 2)\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n",
    "    if i != 1:\n",
    "        continue\n",
    "    print(f\"Fold = {i}\")\n",
    "    train_ids = metadata.loc[train_index, 'Id']\n",
    "    valid_ids = metadata.loc[valid_index, 'Id']\n",
    "    print(f\"Length of Train = {len(train_ids)}, Length of Valid = {len(valid_ids)}\")\n",
    "    \n",
    "    if i == 2:\n",
    "        break\n",
    "        \n",
    "train_fpaths_de = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/{_id}.csv\" for _id in train_ids]\n",
    "valid_fpaths_de = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/{_id}.csv\" for _id in valid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f02c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:57:13.048134Z",
     "iopub.status.busy": "2023-06-08T09:57:13.047777Z",
     "iopub.status.idle": "2023-06-08T09:57:13.053742Z",
     "shell.execute_reply": "2023-06-08T09:57:13.052667Z"
    },
    "papermill": {
     "duration": 0.033683,
     "end_time": "2023-06-08T09:57:13.055904",
     "exception": false,
     "start_time": "2023-06-08T09:57:13.022221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_fpaths = [(f, 'de') for f in train_fpaths_de] + [(f, 'tdcs') for f in train_fpaths_tdcs]\n",
    "valid_fpaths = [(f, 'de') for f in valid_fpaths_de] + [(f, 'tdcs') for f in valid_fpaths_tdcs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa8ce50",
   "metadata": {
    "papermill": {
     "duration": 0.024562,
     "end_time": "2023-06-08T09:57:13.104890",
     "exception": false,
     "start_time": "2023-06-08T09:57:13.080328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataLoader\n",
    "\n",
    "We use a window comprised of past and future time Acc readings to form our dataset for a particular time instance. In case some portion of the window data is not available, we pad them with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e02d3d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:57:13.156240Z",
     "iopub.status.busy": "2023-06-08T09:57:13.155875Z",
     "iopub.status.idle": "2023-06-08T09:57:13.177412Z",
     "shell.execute_reply": "2023-06-08T09:57:13.176401Z"
    },
    "papermill": {
     "duration": 0.050253,
     "end_time": "2023-06-08T09:57:13.179835",
     "exception": false,
     "start_time": "2023-06-08T09:57:13.129582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FOGDataset1(Dataset):\n",
    "    def __init__(self, fpaths, datacfg, scale=9.806, split=\"train\"):\n",
    "        super(FOGDataset, self).__init__()\n",
    "        tm = time.time()\n",
    "        self.split = split\n",
    "        self.scale = scale\n",
    "        self.datacfg = datacfg\n",
    "        self.fpaths = fpaths\n",
    "        self.dfs = [self.read(f[0], f[1]) for f in fpaths]\n",
    "        self.f_ids = [os.path.basename(f[0])[:-4] for f in self.fpaths]\n",
    "        \n",
    "        self.end_indices = []\n",
    "        self.shapes = []\n",
    "        _length = 0\n",
    "        for df in self.dfs:\n",
    "            self.shapes.append(df.shape[0])\n",
    "            _length += df.shape[0]\n",
    "            self.end_indices.append(_length)\n",
    "        \n",
    "        self.dfs = np.concatenate(self.dfs, axis=0).astype(np.float16)\n",
    "        self.length = self.dfs.shape[0]\n",
    "        \n",
    "        shape1 = self.dfs.shape[1]\n",
    "        \n",
    "        self.dfs = np.concatenate([np.zeros((cfg.wx*cfg.window_past, shape1)), self.dfs, np.zeros((cfg.wx*cfg.window_future, shape1))], axis=0)\n",
    "        print(f\"Dataset initialized in {time.time() - tm} secs!\")\n",
    "        gc.collect()\n",
    "        \n",
    "    def read(self, f, _type):\n",
    "        df = pd.read_csv(f)\n",
    "        if self.split == \"test\":\n",
    "            return np.array(df)\n",
    "        \n",
    "        if _type ==\"tdcs\":\n",
    "            df['Valid'] = 1\n",
    "            df['Task'] = 1\n",
    "            df['tdcs'] = 1\n",
    "        else:\n",
    "            df['tdcs'] = 0\n",
    "        \n",
    "        return np.array(df)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.split == \"train\":\n",
    "            row_idx = random.randint(0, self.length-1) + cfg.wx*cfg.window_past\n",
    "        elif self.split == \"test\":\n",
    "            for i,e in enumerate(self.end_indices):\n",
    "                if index >= e:\n",
    "                    continue\n",
    "                df_idx = i\n",
    "                break\n",
    "\n",
    "            row_idx_true = self.shapes[df_idx] - (self.end_indices[df_idx] - index)\n",
    "            _id = self.f_ids[df_idx] + \"_\" + str(row_idx_true)\n",
    "            row_idx = index + cfg.wx*cfg.window_past\n",
    "        else:\n",
    "            row_idx = index + cfg.wx*cfg.window_past\n",
    "            \n",
    "        #scale = 9.806 if self.dfs[row_idx, -1] == 1 else 1.0\n",
    "        x = self.dfs[\n",
    "            row_idx - self.datacfg.wx*self.datacfg.window_past : \\\n",
    "            row_idx + self.datacfg.wx*self.datacfg.window_future, 1:4\n",
    "        ]\n",
    "        x = x[::self.datacfg.wx, :][::-1, :]\n",
    "        x = torch.tensor(x.astype('float'))#/scale\n",
    "        \n",
    "        t = self.dfs[row_idx, -3]*self.dfs[row_idx, -2]\n",
    "        \n",
    "        if self.split == \"test\":\n",
    "            return _id, x, t\n",
    "        \n",
    "        y = self.dfs[row_idx, 4:7].astype('float')\n",
    "        y = torch.tensor(y)\n",
    "        \n",
    "        return x, y, t\n",
    "    \n",
    "    def __len__(self):\n",
    "        # return self.length\n",
    "        if self.split == \"train\":\n",
    "            return 5_000_000\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b9640f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:57:13.231630Z",
     "iopub.status.busy": "2023-06-08T09:57:13.231289Z",
     "iopub.status.idle": "2023-06-08T09:57:13.254221Z",
     "shell.execute_reply": "2023-06-08T09:57:13.253242Z"
    },
    "papermill": {
     "duration": 0.051625,
     "end_time": "2023-06-08T09:57:13.256715",
     "exception": false,
     "start_time": "2023-06-08T09:57:13.205090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FOGDataset(Dataset):\n",
    "    def __init__(self, fpaths, datacfg, scale=9.806, split=\"train\"):\n",
    "        super(FOGDataset, self).__init__()\n",
    "        tm = time.time()\n",
    "        self.split = split\n",
    "        self.scale = scale\n",
    "        self.datacfg = datacfg\n",
    "        self.fpaths = fpaths\n",
    "        self.dfs = [self.read(f[0], f[1]) for f in fpaths]\n",
    "        self.f_ids = [os.path.basename(f[0])[:-4] for f in self.fpaths]\n",
    "        \n",
    "        self.end_indices = []\n",
    "        self.shapes = []\n",
    "        _length = 0\n",
    "        for df in self.dfs:\n",
    "            self.shapes.append(df.shape[0])\n",
    "            _length += df.shape[0]\n",
    "            self.end_indices.append(_length)\n",
    "        \n",
    "        self.dfs = np.concatenate(self.dfs, axis=0).astype(np.float16)\n",
    "        self.length = self.dfs.shape[0]\n",
    "        \n",
    "        shape1 = self.dfs.shape[1]\n",
    "        \n",
    "        self.dfs = np.concatenate(\n",
    "            [\n",
    "                np.zeros((datacfg.wx*datacfg.window_past, shape1)), \n",
    "                self.dfs, np.zeros((datacfg.wx*datacfg.window_future, shape1))\n",
    "            ], \n",
    "            axis=0\n",
    "        )\n",
    "        print(f\"Dataset initialized in {time.time() - tm} secs!\")\n",
    "        gc.collect()\n",
    "        \n",
    "    def read(self, f, _type):\n",
    "        df = pd.read_csv(f)\n",
    "        if self.split == \"test\":\n",
    "            return np.array(df)\n",
    "        \n",
    "        if _type ==\"tdcs\":\n",
    "            df['Valid'] = 1\n",
    "            df['Task'] = 1\n",
    "            df['tdcs'] = 1\n",
    "        else:\n",
    "            df['tdcs'] = 0\n",
    "        \n",
    "        return np.array(df)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.split == \"train\":\n",
    "            row_idx = random.randint(0, self.length-1) + self.datacfg.wx*self.datacfg.window_past\n",
    "        elif self.split == \"test\":\n",
    "            for i,e in enumerate(self.end_indices):\n",
    "                if index >= e:\n",
    "                    continue\n",
    "                df_idx = i\n",
    "                break\n",
    "\n",
    "            row_idx_true = self.shapes[df_idx] - (self.end_indices[df_idx] - index)\n",
    "            _id = self.f_ids[df_idx] + \"_\" + str(row_idx_true)\n",
    "            row_idx = index + self.datacfg.wx*self.datacfg.window_past\n",
    "        else:\n",
    "            row_idx = index + self.datacfg.wx*self.datacfg.window_past\n",
    "            \n",
    "        #scale = 9.806 if self.dfs[row_idx, -1] == 1 else 1.0\n",
    "        x = self.dfs[\n",
    "            row_idx - self.datacfg.wx*self.datacfg.window_past : \\\n",
    "            row_idx + self.datacfg.wx*self.datacfg.window_future, 1:4\n",
    "        ]\n",
    "        x = x[::self.datacfg.wx, :][::-1, :]\n",
    "        x = torch.tensor(x.astype('float'))#/scale\n",
    "        \n",
    "        t = self.dfs[row_idx, -3]*self.dfs[row_idx, -2]\n",
    "        \n",
    "        if self.split == \"test\":\n",
    "            return _id, x, t\n",
    "        \n",
    "        y = self.dfs[row_idx, 4:7].astype('float')\n",
    "        y = torch.tensor(y)\n",
    "        \n",
    "        return x, y, t\n",
    "    \n",
    "    def __len__(self):\n",
    "        # return self.length\n",
    "        if self.split == \"train\":\n",
    "            return 5_000_000\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28815b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:57:13.309308Z",
     "iopub.status.busy": "2023-06-08T09:57:13.308300Z",
     "iopub.status.idle": "2023-06-08T09:57:13.315667Z",
     "shell.execute_reply": "2023-06-08T09:57:13.314587Z"
    },
    "papermill": {
     "duration": 0.036344,
     "end_time": "2023-06-08T09:57:13.318040",
     "exception": false,
     "start_time": "2023-06-08T09:57:13.281696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class DataConfig:\n",
    "    train_dir1 = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog\"\n",
    "    train_dir2 = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog\"\n",
    "\n",
    "    batch_size = 1024                              #batch size大小\n",
    "    window_size = 32                               #每次Input的總時序資料長度\n",
    "    window_future = 8                              #取目標時間點後多少為Input\n",
    "    window_past = window_size - window_future      #取目標時間點前多少為Input\n",
    "    \n",
    "    wx = 8                                         #資料padding長度的參數       \n",
    "    \n",
    "    feature_list = ['AccV', 'AccML', 'AccAP']\n",
    "    label_list = ['StartHesitation', 'Turn', 'Walking']\n",
    "\n",
    "datacfg = DataConfig()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072a2e68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:57:13.369798Z",
     "iopub.status.busy": "2023-06-08T09:57:13.369384Z",
     "iopub.status.idle": "2023-06-08T09:58:09.098150Z",
     "shell.execute_reply": "2023-06-08T09:58:09.096488Z"
    },
    "papermill": {
     "duration": 55.758332,
     "end_time": "2023-06-08T09:58:09.100907",
     "exception": false,
     "start_time": "2023-06-08T09:57:13.342575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized in 42.650877237319946 secs!\n",
      "Dataset initialized in 12.80724287033081 secs!\n",
      "lengths of datasets: train - 5000000, valid - 4984740\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FOGDataset(train_fpaths, datacfg, split=\"train\")\n",
    "valid_dataset = FOGDataset(valid_fpaths, datacfg, split=\"valid\")\n",
    "print(f\"lengths of datasets: train - {len(train_dataset)}, valid - {len(valid_dataset)}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=datacfg.batch_size, num_workers=5, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=datacfg.batch_size, num_workers=5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33d693c6",
   "metadata": {
    "papermill": {
     "duration": 0.024628,
     "end_time": "2023-06-08T09:58:09.150711",
     "exception": false,
     "start_time": "2023-06-08T09:58:09.126083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training kits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e999e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:58:09.202633Z",
     "iopub.status.busy": "2023-06-08T09:58:09.202245Z",
     "iopub.status.idle": "2023-06-08T09:58:09.222599Z",
     "shell.execute_reply": "2023-06-08T09:58:09.221487Z"
    },
    "papermill": {
     "duration": 0.049277,
     "end_time": "2023-06-08T09:58:09.224956",
     "exception": false,
     "start_time": "2023-06-08T09:58:09.175679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "def count_parameters(model:nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, cfg):\n",
    "    loss_sum = 0.\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    model.train()\n",
    "    for x,y,t in tqdm(loader):                               #從DataLoader中取得一個Batch size的資料\n",
    "        x = x.to(cfg.device).float()\n",
    "        y = y.to(cfg.device).float()\n",
    "        t = t.to(cfg.device).float()\n",
    "        \n",
    "        y_pred = model(x)                                    #將Input x丟入模型，得到y_pred\n",
    "        loss = criterion(y_pred, y)                          #計算預測結果y_pred與GT y的loss\n",
    "        loss = torch.mean(loss*t.unsqueeze(-1), dim=1)\n",
    "        \n",
    "        t_sum = torch.sum(t)\n",
    "        if t_sum > 0:\n",
    "            loss = torch.sum(loss)/t_sum\n",
    "        else:\n",
    "            loss = torch.sum(loss)*0.\n",
    "        \n",
    "        # loss.backward()\n",
    "        scaler.scale(loss).backward()                        #根據loss做反向傳播\n",
    "        # optimizer.step()\n",
    "        scaler.step(optimizer)                               #優化器優化模型參數\n",
    "        scaler.update()                                      \n",
    "        \n",
    "        optimizer.zero_grad()                                #優化器歸零\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "    total_loss = (loss_sum/len(loader))\n",
    "    print(f\"Train Loss: {total_loss:.04f}\")\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def validation_one_epoch(model, loader, criterion, cfg):\n",
    "    loss_sum = 0.\n",
    "    y_true_epoch = []\n",
    "    y_pred_epoch = []\n",
    "    t_valid_epoch = []\n",
    "    \n",
    "    model.eval()\n",
    "    for x,y,t in tqdm(loader):\n",
    "        x = x.to(cfg.device).float()\n",
    "        y = y.to(cfg.device).float()\n",
    "        t = t.to(cfg.device).float()\n",
    "        \n",
    "        with torch.no_grad():                                #沒有反向傳播\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss = torch.mean(loss*t.unsqueeze(-1), dim=1)\n",
    "            \n",
    "            t_sum = torch.sum(t)\n",
    "            if t_sum > 0:\n",
    "                loss = torch.sum(loss)/t_sum\n",
    "            else:\n",
    "                loss = torch.sum(loss)*0.\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        y_true_epoch.append(y.cpu().numpy())\n",
    "        y_pred_epoch.append(y_pred.cpu().numpy())\n",
    "        t_valid_epoch.append(t.cpu().numpy())\n",
    "        \n",
    "    y_true_epoch = np.concatenate(y_true_epoch, axis=0)\n",
    "    y_pred_epoch = np.concatenate(y_pred_epoch, axis=0)\n",
    "    \n",
    "    t_valid_epoch = np.concatenate(t_valid_epoch, axis=0)\n",
    "    y_true_epoch = y_true_epoch[t_valid_epoch > 0, :]\n",
    "    y_pred_epoch = y_pred_epoch[t_valid_epoch > 0, :]\n",
    "    \n",
    "    scores = [average_precision_score(y_true_epoch[:,i], y_pred_epoch[:,i]) for i in range(3)]\n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"Validation Loss: {(loss_sum/len(loader)):.04f}, Validation Score: {mean_score:.03f}, ClassWise: {scores[0]:.03f},{scores[1]:.03f},{scores[2]:.03f}\")\n",
    "    \n",
    "    return mean_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af011777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:58:09.276660Z",
     "iopub.status.busy": "2023-06-08T09:58:09.275953Z",
     "iopub.status.idle": "2023-06-08T09:58:09.446840Z",
     "shell.execute_reply": "2023-06-08T09:58:09.444449Z"
    },
    "papermill": {
     "duration": 0.201054,
     "end_time": "2023-06-08T09:58:09.451093",
     "exception": false,
     "start_time": "2023-06-08T09:58:09.250039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcb469b3",
   "metadata": {
    "papermill": {
     "duration": 0.041202,
     "end_time": "2023-06-08T09:58:09.541658",
     "exception": false,
     "start_time": "2023-06-08T09:58:09.500456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Build Model & Optr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a8ba08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:58:09.613312Z",
     "iopub.status.busy": "2023-06-08T09:58:09.612502Z",
     "iopub.status.idle": "2023-06-08T09:58:12.184554Z",
     "shell.execute_reply": "2023-06-08T09:58:12.183454Z"
    },
    "papermill": {
     "duration": 2.610312,
     "end_time": "2023-06-08T09:58:12.186970",
     "exception": false,
     "start_time": "2023-06-08T09:58:09.576658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in model - 3,254,211\n"
     ]
    }
   ],
   "source": [
    "class ResNet20(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_channel, pooling_kernelsize = 3) -> None:\n",
    "        super(ResNet20, self).__init__()       \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(feature_channel, 16, 3, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.ResBlocks = nn.Sequential(\n",
    "            self.__ResBlock(16, 16),\n",
    "            self.__ResBlock(16, 32),\n",
    "            self.__ResBlock(32, 64),\n",
    "        )\n",
    "        self.poolkernelsize = pooling_kernelsize\n",
    "    \n",
    "    class ResidualBlock(nn.Module) :\n",
    "    \n",
    "        def __init__(self, in_channel, out_channel) -> None:\n",
    "            super().__init__()\n",
    "            self.seq =nn.Sequential(\n",
    "                nn.Conv1d(in_channel, out_channel,3,padding=1),\n",
    "                nn.BatchNorm1d(out_channel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv1d(out_channel, out_channel, 3,padding=1),\n",
    "                nn.BatchNorm1d(out_channel)\n",
    "            )\n",
    "            self.neck = nn.Sequential()\n",
    "            if in_channel != out_channel:\n",
    "                self.neck = nn.Sequential(\n",
    "                    nn.Conv1d(in_channel, out_channel,3,padding=1),\n",
    "                    nn.BatchNorm1d(out_channel)\n",
    "                )\n",
    "        \n",
    "        def forward(self, x)->torch.Tensor:\n",
    "            return F.relu(self.seq(x) + self.neck(x))\n",
    "\n",
    "    def __ResBlock(self,cin, cout):\n",
    "        clist = [(cin, cout), (cout, cout), (cout, cout)]\n",
    "        return nn.Sequential(\n",
    "            *list(self.ResidualBlock(ci, co) for ci, co in clist)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x)->torch.Tensor :\n",
    "        x1 = self.conv1(x.permute(0,2,1))\n",
    "        x1 = self.ResBlocks(x1)\n",
    "        x1 = x1.permute(0,2,1)\n",
    "        if self.poolkernelsize > 1:\n",
    "            x1 = F.avg_pool1d(x1, kernel_size=self.poolkernelsize)\n",
    "        return x1.reshape(x1.shape[0], -1) #flatten\n",
    "\n",
    "\n",
    "class ResConvClassifier(nn.Module):\n",
    "    def __init__(\n",
    "            self, feature_channels, seqlen, out_features, \n",
    "            classifier_layers=[128], resnet_pooling_kernelsize = 1\n",
    "        ) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        ResetNet20 output dimensions = floor(64/resnet_pooling_kernelsize)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        super(ResConvClassifier, self).__init__()\n",
    "        self.emd = ResNet20(feature_channels,resnet_pooling_kernelsize)\n",
    "        \n",
    "        assert resnet_pooling_kernelsize > 0\n",
    "        resnet_out = seqlen*int(math.floor(64.0/float(resnet_pooling_kernelsize)))\n",
    "        \n",
    "        layers = [resnet_out] + classifier_layers + [out_features]\n",
    "        if (layers[1] > layers[0]):\n",
    "            print(f\"Waring ! Resnet20 output are {layers[0]}\")\n",
    "            print(f\"and you give {layers[1]}, try to lift dimension ????? \")\n",
    "        if (layers[-1] > classifier_layers[-2]):\n",
    "            print(f\"Waring ! output are {classifier_layers[-1]}\")\n",
    "            print(f\"and you give {classifier_layers[-2]}, try to lift dimension ????? \")\n",
    "        \n",
    "        c = []\n",
    "        j = -1\n",
    "        for i in range(len(classifier_layers)):\n",
    "            c.append(self.__LinBlock(layers[i],layers[i+1]))\n",
    "            j = i\n",
    "        c.append(nn.Linear(layers[j+1],layers[j+2]))\n",
    "        self.classifier = nn.Sequential(*c)\n",
    "\n",
    "    def __LinBlock(self, ind, outd)->nn.Sequential:\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(ind, outd),\n",
    "            nn.BatchNorm1d(outd),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x1 = self.emd(x)\n",
    "        x1 = self.classifier(x1)\n",
    "        return x1\n",
    "\n",
    "class Config:\n",
    "    \n",
    "    optimizer_name = \"Adam\"                       \n",
    "    loss_function = \"BCEWithLogitsLoss\"           \n",
    "    lr = 0.01                           \n",
    "    num_epochs = 50                             \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'         \n",
    "    classifier_layers = [1024,1024]\n",
    "    pooling_kernel = 1\n",
    "    \n",
    "cfg = Config()\n",
    "    \n",
    "\n",
    "model = ResConvClassifier(\n",
    "    feature_channels=len(datacfg.feature_list), \n",
    "    seqlen=datacfg.window_size, \n",
    "    out_features=len(datacfg.label_list), \n",
    "    resnet_pooling_kernelsize = cfg.pooling_kernel,\n",
    "    classifier_layers = cfg.classifier_layers\n",
    ").to(cfg.device)\n",
    "print(f\"Number of parameters in model - {count_parameters(model):,}\")\n",
    "\n",
    "optimizer = getattr(torch.optim, cfg.optimizer_name)(model.parameters(), lr=cfg.lr)\n",
    "criterion = getattr(torch.nn, cfg.loss_function)(reduction='none').to(cfg.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19d02665",
   "metadata": {
    "papermill": {
     "duration": 0.024891,
     "end_time": "2023-06-08T09:58:12.237031",
     "exception": false,
     "start_time": "2023-06-08T09:58:12.212140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f537196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T09:58:12.289943Z",
     "iopub.status.busy": "2023-06-08T09:58:12.288933Z",
     "iopub.status.idle": "2023-06-08T17:32:23.466253Z",
     "shell.execute_reply": "2023-06-08T17:32:23.465131Z"
    },
    "papermill": {
     "duration": 27255.952483,
     "end_time": "2023-06-08T17:32:28.214809",
     "exception": false,
     "start_time": "2023-06-08T09:58:12.262326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:26<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0871, Validation Score: 0.240, ClassWise: 0.053,0.609,0.058\n",
      "Saving Model ...\n",
      "==================================================\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:21<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:33<00:00, 31.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1114, Validation Score: 0.250, ClassWise: 0.031,0.693,0.026\n",
      "Saving Model ...\n",
      "==================================================\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:24<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:35<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1320, Validation Score: 0.258, ClassWise: 0.034,0.690,0.049\n",
      "Saving Model ...\n",
      "==================================================\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:24<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1797, Validation Score: 0.245, ClassWise: 0.020,0.678,0.039\n",
      "==================================================\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:26<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:38<00:00, 30.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1789, Validation Score: 0.215, ClassWise: 0.034,0.573,0.037\n",
      "==================================================\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:28<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1799, Validation Score: 0.245, ClassWise: 0.032,0.672,0.033\n",
      "==================================================\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:22<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:35<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1822, Validation Score: 0.249, ClassWise: 0.065,0.647,0.034\n",
      "==================================================\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:25<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1788, Validation Score: 0.244, ClassWise: 0.052,0.642,0.036\n",
      "==================================================\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:28<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2065, Validation Score: 0.242, ClassWise: 0.040,0.641,0.045\n",
      "==================================================\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:27<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:40<00:00, 30.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2521, Validation Score: 0.225, ClassWise: 0.027,0.614,0.035\n",
      "==================================================\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:25<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:40<00:00, 30.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2439, Validation Score: 0.228, ClassWise: 0.036,0.611,0.037\n",
      "==================================================\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:28<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2619, Validation Score: 0.236, ClassWise: 0.026,0.640,0.043\n",
      "==================================================\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:25<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:38<00:00, 30.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2659, Validation Score: 0.246, ClassWise: 0.031,0.656,0.051\n",
      "==================================================\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:27<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:36<00:00, 31.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2988, Validation Score: 0.221, ClassWise: 0.034,0.589,0.040\n",
      "==================================================\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:25<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:36<00:00, 31.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2783, Validation Score: 0.248, ClassWise: 0.035,0.663,0.045\n",
      "==================================================\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:26<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2897, Validation Score: 0.236, ClassWise: 0.033,0.629,0.046\n",
      "==================================================\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:28<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:35<00:00, 31.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2554, Validation Score: 0.244, ClassWise: 0.050,0.640,0.041\n",
      "==================================================\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:23<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:35<00:00, 31.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3163, Validation Score: 0.239, ClassWise: 0.027,0.643,0.048\n",
      "==================================================\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:23<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3223, Validation Score: 0.241, ClassWise: 0.029,0.654,0.040\n",
      "==================================================\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:23<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3056, Validation Score: 0.239, ClassWise: 0.037,0.639,0.040\n",
      "==================================================\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:23<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3565, Validation Score: 0.241, ClassWise: 0.026,0.655,0.041\n",
      "==================================================\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:23<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 31.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3346, Validation Score: 0.239, ClassWise: 0.041,0.637,0.038\n",
      "==================================================\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:25<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:36<00:00, 31.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3381, Validation Score: 0.238, ClassWise: 0.028,0.636,0.049\n",
      "==================================================\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:26<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:33<00:00, 31.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3344, Validation Score: 0.234, ClassWise: 0.035,0.618,0.048\n",
      "==================================================\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:24<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:31<00:00, 32.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3282, Validation Score: 0.247, ClassWise: 0.034,0.663,0.044\n",
      "==================================================\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:22<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:32<00:00, 31.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3210, Validation Score: 0.231, ClassWise: 0.033,0.617,0.041\n",
      "==================================================\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:24<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:35<00:00, 31.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3498, Validation Score: 0.227, ClassWise: 0.049,0.587,0.045\n",
      "==================================================\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:22<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:38<00:00, 30.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3948, Validation Score: 0.235, ClassWise: 0.040,0.616,0.048\n",
      "==================================================\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:22<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:38<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3866, Validation Score: 0.241, ClassWise: 0.029,0.647,0.045\n",
      "==================================================\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:22<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3923, Validation Score: 0.233, ClassWise: 0.028,0.622,0.049\n",
      "==================================================\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:20<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3832, Validation Score: 0.242, ClassWise: 0.030,0.652,0.044\n",
      "==================================================\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:20<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:38<00:00, 30.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3837, Validation Score: 0.239, ClassWise: 0.032,0.639,0.045\n",
      "==================================================\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:20<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3923, Validation Score: 0.241, ClassWise: 0.031,0.646,0.046\n",
      "==================================================\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:20<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3880, Validation Score: 0.238, ClassWise: 0.034,0.636,0.044\n",
      "==================================================\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:20<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:38<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4145, Validation Score: 0.249, ClassWise: 0.033,0.666,0.049\n",
      "==================================================\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:20<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4666, Validation Score: 0.236, ClassWise: 0.025,0.639,0.044\n",
      "==================================================\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:19<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:37<00:00, 30.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4225, Validation Score: 0.241, ClassWise: 0.032,0.638,0.053\n",
      "==================================================\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:19<00:00, 12.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:36<00:00, 31.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4527, Validation Score: 0.230, ClassWise: 0.028,0.611,0.052\n",
      "==================================================\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:20<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:36<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4574, Validation Score: 0.234, ClassWise: 0.030,0.619,0.053\n",
      "==================================================\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:25<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4098, Validation Score: 0.243, ClassWise: 0.032,0.640,0.057\n",
      "==================================================\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:24<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4567, Validation Score: 0.242, ClassWise: 0.029,0.646,0.051\n",
      "==================================================\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:27<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:40<00:00, 30.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4333, Validation Score: 0.244, ClassWise: 0.028,0.651,0.051\n",
      "==================================================\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:26<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4220, Validation Score: 0.242, ClassWise: 0.043,0.633,0.050\n",
      "==================================================\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:22<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:36<00:00, 31.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4758, Validation Score: 0.236, ClassWise: 0.029,0.633,0.046\n",
      "==================================================\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:22<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:35<00:00, 31.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4509, Validation Score: 0.245, ClassWise: 0.033,0.657,0.047\n",
      "==================================================\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:24<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:38<00:00, 30.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4803, Validation Score: 0.241, ClassWise: 0.032,0.638,0.053\n",
      "==================================================\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:27<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:40<00:00, 30.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4793, Validation Score: 0.239, ClassWise: 0.030,0.639,0.047\n",
      "==================================================\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:28<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:43<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4688, Validation Score: 0.246, ClassWise: 0.027,0.651,0.059\n",
      "==================================================\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:28<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4707, Validation Score: 0.243, ClassWise: 0.034,0.648,0.049\n",
      "==================================================\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [06:28<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4868/4868 [02:39<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4810, Validation Score: 0.242, ClassWise: 0.032,0.643,0.052\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_per_iter = []\n",
    "valid_per_iter = []\n",
    "max_score = 0.0\n",
    "#sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.85)\n",
    "for epoch in range(cfg.num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    loss = train_one_epoch(model, train_loader, optimizer, criterion,cfg)\n",
    "    score = validation_one_epoch(model, valid_loader, criterion, cfg)\n",
    "    #sched.step()\n",
    "    loss_per_iter.append(loss)\n",
    "    valid_per_iter.append(score)\n",
    "    \n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        torch.save(model.state_dict(), \"best_model_state_b1.h5\")      #儲存最好的模型參數\n",
    "        print(\"Saving Model ...\")\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "290fbcba",
   "metadata": {
    "papermill": {
     "duration": 15.204291,
     "end_time": "2023-06-08T17:32:59.048577",
     "exception": false,
     "start_time": "2023-06-08T17:32:43.844286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fc37b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T17:33:29.630580Z",
     "iopub.status.busy": "2023-06-08T17:33:29.630168Z",
     "iopub.status.idle": "2023-06-08T17:33:36.757975Z",
     "shell.execute_reply": "2023-06-08T17:33:36.756727Z"
    },
    "papermill": {
     "duration": 22.222701,
     "end_time": "2023-06-08T17:33:36.762228",
     "exception": false,
     "start_time": "2023-06-08T17:33:14.539527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized in 0.4898190498352051 secs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:06<00:00, 43.78it/s]\n"
     ]
    }
   ],
   "source": [
    "model =ResConvClassifier(\n",
    "    feature_channels=len(datacfg.feature_list), \n",
    "    seqlen=datacfg.window_size, \n",
    "    out_features=len(datacfg.label_list), \n",
    "    resnet_pooling_kernelsize = cfg.pooling_kernel,\n",
    "    classifier_layers = cfg.classifier_layers\n",
    ").to(cfg.device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/best_model_state_b1.h5\"))             #取得最好的模型參數\n",
    "model.eval()\n",
    "\n",
    "test_defog_paths = glob.glob(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/*.csv\")\n",
    "test_tdcsfog_paths = glob.glob(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/*.csv\")\n",
    "test_fpaths = [(f, 'de') for f in test_defog_paths] + [(f, 'tdcs') for f in test_tdcsfog_paths]\n",
    "\n",
    "test_dataset = FOGDataset(test_fpaths, datacfg, split=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=datacfg.batch_size, num_workers=5)\n",
    "\n",
    "ids = []\n",
    "preds = []\n",
    "\n",
    "for _id, x, _ in tqdm(test_loader):\n",
    "    x = x.to(cfg.device).float()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x)*0.1\n",
    "    \n",
    "    ids.extend(_id)\n",
    "    preds.extend(list(np.nan_to_num(y_pred.cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8166cd19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T17:34:06.455501Z",
     "iopub.status.busy": "2023-06-08T17:34:06.454288Z",
     "iopub.status.idle": "2023-06-08T17:34:06.696475Z",
     "shell.execute_reply": "2023-06-08T17:34:06.695398Z"
    },
    "papermill": {
     "duration": 15.077309,
     "end_time": "2023-06-08T17:34:06.698993",
     "exception": false,
     "start_time": "2023-06-08T17:33:51.621684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286370, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv\")\n",
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "942e2ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T17:34:37.071141Z",
     "iopub.status.busy": "2023-06-08T17:34:37.070736Z",
     "iopub.status.idle": "2023-06-08T17:34:38.769703Z",
     "shell.execute_reply": "2023-06-08T17:34:38.768564Z"
    },
    "papermill": {
     "duration": 16.888813,
     "end_time": "2023-06-08T17:34:38.772189",
     "exception": false,
     "start_time": "2023-06-08T17:34:21.883376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286370, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>StartHesitation</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003f117e14_0</td>\n",
       "      <td>-2.70163</td>\n",
       "      <td>-1.68212</td>\n",
       "      <td>-2.13139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f117e14_1</td>\n",
       "      <td>-2.71000</td>\n",
       "      <td>-1.68383</td>\n",
       "      <td>-2.14018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003f117e14_2</td>\n",
       "      <td>-2.70809</td>\n",
       "      <td>-1.68727</td>\n",
       "      <td>-2.14271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003f117e14_3</td>\n",
       "      <td>-2.70233</td>\n",
       "      <td>-1.68228</td>\n",
       "      <td>-2.11908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003f117e14_4</td>\n",
       "      <td>-2.70912</td>\n",
       "      <td>-1.68913</td>\n",
       "      <td>-2.13474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  StartHesitation     Turn  Walking\n",
       "0  003f117e14_0         -2.70163 -1.68212 -2.13139\n",
       "1  003f117e14_1         -2.71000 -1.68383 -2.14018\n",
       "2  003f117e14_2         -2.70809 -1.68727 -2.14271\n",
       "3  003f117e14_3         -2.70233 -1.68228 -2.11908\n",
       "4  003f117e14_4         -2.70912 -1.68913 -2.13474"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.array(preds)\n",
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        'Id': ids, \n",
    "        'StartHesitation': np.round(preds[:,0],5),                 \n",
    "        'Turn': np.round(preds[:,1],5), \n",
    "        'Walking': np.round(preds[:,2],5)\n",
    "    }\n",
    ")\n",
    "\n",
    "submission = pd.merge(sample_submission[['Id']], submission, how='left', on='Id').fillna(0.0)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27519.932411,
   "end_time": "2023-06-08T17:34:56.440520",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-08T09:56:16.508109",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
