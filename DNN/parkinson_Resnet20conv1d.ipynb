{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Copy from https://www.kaggle.com/code/mayukh18/pytorch-fog-end-to-end-baseline-lb-0-254"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-08T14:57:38.928938Z","iopub.status.busy":"2023-06-08T14:57:38.928476Z","iopub.status.idle":"2023-06-08T14:57:43.058112Z","shell.execute_reply":"2023-06-08T14:57:43.056649Z","shell.execute_reply.started":"2023-06-08T14:57:38.928893Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Env set ok ..\n"]}],"source":["import os\n","import gc\n","import random\n","import time\n","import math\n","import json\n","from tqdm import tqdm\n","import glob\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n","from sklearn.metrics import accuracy_score, average_precision_score\n","\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","print(\"Env set ok ..\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Stratified Group K Fold\n","\n","It's mentioned in the data that the subjects are different in the train and test set and even different between the public/private splits of the test data. So we need to use Stratified Group K Fold. But since the positive instances in the sequences are very scarce, we need to pick up the best fold which will give us the best balance of the positive/negative instances."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### tdcsfog preprocessing"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:57:55.884633Z","iopub.status.busy":"2023-06-08T14:57:55.884009Z","iopub.status.idle":"2023-06-08T14:58:17.751073Z","shell.execute_reply":"2023-06-08T14:58:17.749878Z","shell.execute_reply.started":"2023-06-08T14:57:55.884590Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 833/833 [00:21<00:00, 38.36it/s]"]},{"name":"stdout","output_type":"stream","text":["32 files have positive values in all 3 classes\n","Fold = 0\n","Length of Train = 672, Length of Valid = 161\n","Train classes: 287,832, 1,462,652, 175,633\n","Valid classes: 16,958, 216,130, 32,205\n","Fold = 1\n","Length of Train = 613, Length of Valid = 220\n","Train classes: 51,748, 909,505, 65,242\n","Valid classes: 253,042, 769,277, 142,596\n","Fold = 2\n","Length of Train = 703, Length of Valid = 130\n","Train classes: 271,881, 1,332,746, 183,673\n","Valid classes: 32,909, 346,036, 24,165\n","Fold = 3\n","Length of Train = 649, Length of Valid = 184\n","Train classes: 303,710, 1,517,147, 205,196\n","Valid classes: 1,080, 161,635, 2,642\n","Fold = 4\n","Length of Train = 695, Length of Valid = 138\n","Train classes: 303,989, 1,493,078, 201,608\n","Valid classes: 801, 185,704, 6,230\n","Fold = 2\n","Length of Train = 703, Length of Valid = 130\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Analysis of positive instances in each fold of our CV folds\n","\n","n1_sum = []\n","n2_sum = []\n","n3_sum = []\n","count = []\n","\n","# Here I am using the metadata file available during training. Since the code \n","# will run again during submission, if \n","# I used the usual file from the competition folder, \n","# it would have been updated with the test files too.\n","metadata = pd.read_csv(\"/kaggle/input/copy-train-metadata/tdcsfog_metadata.csv\")\n","\n","for f in tqdm(metadata['Id']):\n","    fpath = f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{f}.csv\"\n","    df = pd.read_csv(fpath)\n","    \n","    n1_sum.append(np.sum(df['StartHesitation']))\n","    n2_sum.append(np.sum(df['Turn']))\n","    n3_sum.append(np.sum(df['Walking']))\n","    count.append(len(df))\n","    \n","print(f\"32 files have positive values in all 3 classes\")\n","\n","metadata['n1_sum'] = n1_sum\n","metadata['n2_sum'] = n2_sum\n","metadata['n3_sum'] = n3_sum\n","metadata['count'] = count\n","\n","sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n","for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n","    print(f\"Fold = {i}\")\n","    train_ids = metadata.loc[train_index, 'Id']\n","    valid_ids = metadata.loc[valid_index, 'Id']\n","    \n","    print(f\"Length of Train = {len(train_index)}, Length of Valid = {len(valid_index)}\")\n","    n1_sum = metadata.loc[train_index, 'n1_sum'].sum()\n","    n2_sum = metadata.loc[train_index, 'n2_sum'].sum()\n","    n3_sum = metadata.loc[train_index, 'n3_sum'].sum()\n","    print(f\"Train classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n","    \n","    n1_sum = metadata.loc[valid_index, 'n1_sum'].sum()\n","    n2_sum = metadata.loc[valid_index, 'n2_sum'].sum()\n","    n3_sum = metadata.loc[valid_index, 'n3_sum'].sum()\n","    print(f\"Valid classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n","    \n","# FOLD 2 is the most well balanced\n","# The actual train-test split (based on Fold 2)\n","\n","metadata = pd.read_csv(\"/kaggle/input/copy-train-metadata/tdcsfog_metadata.csv\")\n","sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n","for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n","    if i != 2:\n","        continue\n","    print(f\"Fold = {i}\")\n","    train_ids = metadata.loc[train_index, 'Id']\n","    valid_ids = metadata.loc[valid_index, 'Id']\n","    print(f\"Length of Train = {len(train_ids)}, Length of Valid = {len(valid_ids)}\")\n","    \n","    if i == 2:\n","        break\n","        \n","train_fpaths_tdcs = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{_id}.csv\" for _id in train_ids]\n","valid_fpaths_tdcs = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/{_id}.csv\" for _id in valid_ids]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### defog preprocessing"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:58:53.202414Z","iopub.status.busy":"2023-06-08T14:58:53.201980Z","iopub.status.idle":"2023-06-08T14:59:09.075367Z","shell.execute_reply":"2023-06-08T14:59:09.073979Z","shell.execute_reply.started":"2023-06-08T14:58:53.202372Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 137/137 [00:15<00:00,  8.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Fold = 0\n","Length of Train = 75, Length of Valid = 16\n","Train classes: 500, 428,683, 37,609\n","Valid classes: 0, 158,803, 60,910\n","Fold = 1\n","Length of Train = 65, Length of Valid = 26\n","Train classes: 216, 490,429, 84,955\n","Valid classes: 284, 97,057, 13,564\n","Fold = 2\n","Length of Train = 76, Length of Valid = 15\n","Train classes: 410, 488,634, 87,986\n","Valid classes: 90, 98,852, 10,533\n","Fold = 3\n","Length of Train = 70, Length of Valid = 21\n","Train classes: 435, 424,494, 88,800\n","Valid classes: 65, 162,992, 9,719\n","Fold = 4\n","Length of Train = 78, Length of Valid = 13\n","Train classes: 439, 517,704, 94,726\n","Valid classes: 61, 69,782, 3,793\n","Fold = 1\n","Length of Train = 65, Length of Valid = 26\n"]}],"source":["# Analysis of positive instances in each fold of our CV folds\n","\n","n1_sum = []\n","n2_sum = []\n","n3_sum = []\n","count = []\n","\n","# Here I am using the metadata file available during training. Since the code will run again during submission, if \n","# I used the usual file from the competition folder, it would have been updated with the test files too.\n","metadata = pd.read_csv(\"/kaggle/input/copy-train-metadata/defog_metadata.csv\")\n","metadata['n1_sum'] = 0\n","metadata['n2_sum'] = 0\n","metadata['n3_sum'] = 0\n","metadata['count'] = 0\n","\n","for f in tqdm(metadata['Id']):\n","    fpath = f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/{f}.csv\"\n","    if os.path.exists(fpath) == False:\n","        continue\n","        \n","    df = pd.read_csv(fpath)\n","    metadata.loc[metadata['Id'] == f, 'n1_sum'] = np.sum(df['StartHesitation'])\n","    metadata.loc[metadata['Id'] == f, 'n2_sum'] = np.sum(df['Turn'])\n","    metadata.loc[metadata['Id'] == f, 'n3_sum'] = np.sum(df['Walking'])\n","    metadata.loc[metadata['Id'] == f, 'count'] = len(df)\n","    \n","metadata = metadata[metadata['count'] > 0].reset_index()\n","\n","sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n","for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n","    print(f\"Fold = {i}\")\n","    train_ids = metadata.loc[train_index, 'Id']\n","    valid_ids = metadata.loc[valid_index, 'Id']\n","    \n","    print(f\"Length of Train = {len(train_index)}, Length of Valid = {len(valid_index)}\")\n","    n1_sum = metadata.loc[train_index, 'n1_sum'].sum()\n","    n2_sum = metadata.loc[train_index, 'n2_sum'].sum()\n","    n3_sum = metadata.loc[train_index, 'n3_sum'].sum()\n","    print(f\"Train classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n","    \n","    n1_sum = metadata.loc[valid_index, 'n1_sum'].sum()\n","    n2_sum = metadata.loc[valid_index, 'n2_sum'].sum()\n","    n3_sum = metadata.loc[valid_index, 'n3_sum'].sum()\n","    print(f\"Valid classes: {n1_sum:,}, {n2_sum:,}, {n3_sum:,}\")\n","    \n","# FOLD 2 is the most well balanced\n","# The actual train-test split (based on Fold 2)\n","\n","sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n","for i, (train_index, valid_index) in enumerate(sgkf.split(X=metadata['Id'], y=[1]*len(metadata), groups=metadata['Subject'])):\n","    if i != 1:\n","        continue\n","    print(f\"Fold = {i}\")\n","    train_ids = metadata.loc[train_index, 'Id']\n","    valid_ids = metadata.loc[valid_index, 'Id']\n","    print(f\"Length of Train = {len(train_ids)}, Length of Valid = {len(valid_ids)}\")\n","    \n","    if i == 2:\n","        break\n","        \n","train_fpaths_de = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/{_id}.csv\" for _id in train_ids]\n","valid_fpaths_de = [f\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/{_id}.csv\" for _id in valid_ids]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:59:17.939896Z","iopub.status.busy":"2023-06-08T14:59:17.939041Z","iopub.status.idle":"2023-06-08T14:59:17.946907Z","shell.execute_reply":"2023-06-08T14:59:17.945424Z","shell.execute_reply.started":"2023-06-08T14:59:17.939849Z"},"trusted":true},"outputs":[],"source":["train_fpaths = [(f, 'de') for f in train_fpaths_de] + [(f, 'tdcs') for f in train_fpaths_tdcs]\n","valid_fpaths = [(f, 'de') for f in valid_fpaths_de] + [(f, 'tdcs') for f in valid_fpaths_tdcs]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# DataLoader\n","\n","We use a window comprised of past and future time Acc readings to form our dataset for a particular time instance. In case some portion of the window data is not available, we pad them with zeros."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:59:37.367886Z","iopub.status.busy":"2023-06-08T14:59:37.367481Z","iopub.status.idle":"2023-06-08T14:59:37.395728Z","shell.execute_reply":"2023-06-08T14:59:37.394314Z","shell.execute_reply.started":"2023-06-08T14:59:37.367847Z"},"trusted":true},"outputs":[],"source":["class FOGDataset(Dataset):\n","    def __init__(self, fpaths, datacfg, scale=9.806, split=\"train\"):\n","        super(FOGDataset, self).__init__()\n","        tm = time.time()\n","        self.split = split\n","        self.scale = scale\n","        self.datacfg = datacfg\n","        self.fpaths = fpaths\n","        self.dfs = [self.read(f[0], f[1]) for f in fpaths]\n","        self.f_ids = [os.path.basename(f[0])[:-4] for f in self.fpaths]\n","        \n","        self.end_indices = []\n","        self.shapes = []\n","        _length = 0\n","        for df in self.dfs:\n","            self.shapes.append(df.shape[0])\n","            _length += df.shape[0]\n","            self.end_indices.append(_length)\n","        \n","        self.dfs = np.concatenate(self.dfs, axis=0).astype(np.float16)\n","        self.length = self.dfs.shape[0]\n","        \n","        shape1 = self.dfs.shape[1]\n","        \n","        self.dfs = np.concatenate(\n","            [\n","                np.zeros((datacfg.wx*datacfg.window_past, shape1)), \n","                self.dfs, np.zeros((datacfg.wx*datacfg.window_future, shape1))\n","            ], \n","            axis=0\n","        )\n","        print(f\"Dataset initialized in {time.time() - tm} secs!\")\n","        gc.collect()\n","        \n","    def read(self, f, _type):\n","        df = pd.read_csv(f)\n","        if self.split == \"test\":\n","            return np.array(df)\n","        \n","        if _type ==\"tdcs\":\n","            df['Valid'] = 1\n","            df['Task'] = 1\n","            df['tdcs'] = 1\n","        else:\n","            df['tdcs'] = 0\n","        \n","        return np.array(df)\n","            \n","    def __getitem__(self, index):\n","        if self.split == \"train\":\n","            row_idx = random.randint(0, self.length-1) + self.datacfg.wx*self.datacfg.window_past\n","        elif self.split == \"test\":\n","            for i,e in enumerate(self.end_indices):\n","                if index >= e:\n","                    continue\n","                df_idx = i\n","                break\n","\n","            row_idx_true = self.shapes[df_idx] - (self.end_indices[df_idx] - index)\n","            _id = self.f_ids[df_idx] + \"_\" + str(row_idx_true)\n","            row_idx = index + self.datacfg.wx*self.datacfg.window_past\n","        else:\n","            row_idx = index + self.datacfg.wx*self.datacfg.window_past\n","            \n","        #scale = 9.806 if self.dfs[row_idx, -1] == 1 else 1.0\n","        x = self.dfs[\n","            row_idx - self.datacfg.wx*self.datacfg.window_past : \\\n","            row_idx + self.datacfg.wx*self.datacfg.window_future, 1:4\n","        ]\n","        x = x[::self.datacfg.wx, :][::-1, :]\n","        x = torch.tensor(x.astype('float'))#/scale\n","        \n","        t = self.dfs[row_idx, -3]*self.dfs[row_idx, -2]\n","        \n","        if self.split == \"test\":\n","            return _id, x, t\n","        \n","        y = self.dfs[row_idx, 4:7].astype('float')\n","        y = torch.tensor(y)\n","        \n","        return x, y, t\n","    \n","    def __len__(self):\n","        # return self.length\n","        if self.split == \"train\":\n","            return 5_000_000\n","        return self.length"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:59:40.288148Z","iopub.status.busy":"2023-06-08T14:59:40.287610Z","iopub.status.idle":"2023-06-08T14:59:40.296236Z","shell.execute_reply":"2023-06-08T14:59:40.294756Z","shell.execute_reply.started":"2023-06-08T14:59:40.288102Z"},"trusted":true},"outputs":[],"source":["\n","class DataConfig:\n","    train_dir1 = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog\"\n","    train_dir2 = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog\"\n","\n","    batch_size = 1024                              #batch size大小\n","    window_size = 32                               #每次Input的總時序資料長度\n","    window_future = 8                              #取目標時間點後多少為Input\n","    window_past = window_size - window_future      #取目標時間點前多少為Input\n","    \n","    wx = 8                                         #資料padding長度的參數       \n","    \n","    feature_list = ['AccV', 'AccML', 'AccAP']\n","    label_list = ['StartHesitation', 'Turn', 'Walking']\n","\n","datacfg = DataConfig()\n","    "]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T14:59:42.574207Z","iopub.status.busy":"2023-06-08T14:59:42.573756Z","iopub.status.idle":"2023-06-08T15:00:46.990867Z","shell.execute_reply":"2023-06-08T15:00:46.989693Z","shell.execute_reply.started":"2023-06-08T14:59:42.574162Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset initialized in 49.290886878967285 secs!\n","Dataset initialized in 14.815473079681396 secs!\n","lengths of datasets: train - 5000000, valid - 4984740\n"]}],"source":["train_dataset = FOGDataset(train_fpaths, datacfg, split=\"train\")\n","valid_dataset = FOGDataset(valid_fpaths, datacfg, split=\"valid\")\n","print(f\"lengths of datasets: train - {len(train_dataset)}, valid - {len(valid_dataset)}\")\n","train_loader = DataLoader(train_dataset, batch_size=datacfg.batch_size, num_workers=5, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=datacfg.batch_size, num_workers=5)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training kits"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T15:00:52.908047Z","iopub.status.busy":"2023-06-08T15:00:52.906719Z","iopub.status.idle":"2023-06-08T15:00:52.931029Z","shell.execute_reply":"2023-06-08T15:00:52.929897Z","shell.execute_reply.started":"2023-06-08T15:00:52.907996Z"},"trusted":true},"outputs":[],"source":["from torch.cuda.amp import GradScaler\n","\n","def count_parameters(model:nn.Module):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def train_one_epoch(model, loader, optimizer, criterion, cfg):\n","    loss_sum = 0.\n","    scaler = GradScaler()\n","    \n","    model.train()\n","    for x,y,t in tqdm(loader):                               #從DataLoader中取得一個Batch size的資料\n","        x = x.to(cfg.device).float()\n","        y = y.to(cfg.device).float()\n","        t = t.to(cfg.device).float()\n","        \n","        y_pred = model(x)                                    #將Input x丟入模型，得到y_pred\n","        loss = criterion(y_pred, y)                          #計算預測結果y_pred與GT y的loss\n","        loss = torch.mean(loss*t.unsqueeze(-1), dim=1)\n","        \n","        t_sum = torch.sum(t)\n","        if t_sum > 0:\n","            loss = torch.sum(loss)/t_sum\n","        else:\n","            loss = torch.sum(loss)*0.\n","        \n","        # loss.backward()\n","        scaler.scale(loss).backward()                        #根據loss做反向傳播\n","        # optimizer.step()\n","        scaler.step(optimizer)                               #優化器優化模型參數\n","        scaler.update()                                      \n","        \n","        optimizer.zero_grad()                                #優化器歸零\n","        \n","        loss_sum += loss.item()\n","    total_loss = (loss_sum/len(loader))\n","    print(f\"Train Loss: {total_loss:.04f}\")\n","    \n","    return total_loss\n","\n","def validation_one_epoch(model, loader, criterion, cfg):\n","    loss_sum = 0.\n","    y_true_epoch = []\n","    y_pred_epoch = []\n","    t_valid_epoch = []\n","    \n","    model.eval()\n","    for x,y,t in tqdm(loader):\n","        x = x.to(cfg.device).float()\n","        y = y.to(cfg.device).float()\n","        t = t.to(cfg.device).float()\n","        \n","        with torch.no_grad():                                #沒有反向傳播\n","            y_pred = model(x)\n","            loss = criterion(y_pred, y)\n","            loss = torch.mean(loss*t.unsqueeze(-1), dim=1)\n","            \n","            t_sum = torch.sum(t)\n","            if t_sum > 0:\n","                loss = torch.sum(loss)/t_sum\n","            else:\n","                loss = torch.sum(loss)*0.\n","        \n","        loss_sum += loss.item()\n","        y_true_epoch.append(y.cpu().numpy())\n","        y_pred_epoch.append(y_pred.cpu().numpy())\n","        t_valid_epoch.append(t.cpu().numpy())\n","        \n","    y_true_epoch = np.concatenate(y_true_epoch, axis=0)\n","    y_pred_epoch = np.concatenate(y_pred_epoch, axis=0)\n","    \n","    t_valid_epoch = np.concatenate(t_valid_epoch, axis=0)\n","    y_true_epoch = y_true_epoch[t_valid_epoch > 0, :]\n","    y_pred_epoch = y_pred_epoch[t_valid_epoch > 0, :]\n","    \n","    scores = [average_precision_score(y_true_epoch[:,i], y_pred_epoch[:,i]) for i in range(3)]\n","    mean_score = np.mean(scores)\n","    print(f\"Validation Loss: {(loss_sum/len(loader)):.04f}, Validation Score: {mean_score:.03f}, ClassWise: {scores[0]:.03f},{scores[1]:.03f},{scores[2]:.03f}\")\n","    \n","    return mean_score\n","\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T15:00:56.640476Z","iopub.status.busy":"2023-06-08T15:00:56.639724Z","iopub.status.idle":"2023-06-08T15:00:56.799148Z","shell.execute_reply":"2023-06-08T15:00:56.797593Z","shell.execute_reply.started":"2023-06-08T15:00:56.640425Z"},"trusted":true},"outputs":[{"data":{"text/plain":["23"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Build Model & Optr"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T15:01:01.552945Z","iopub.status.busy":"2023-06-08T15:01:01.552066Z","iopub.status.idle":"2023-06-08T15:01:01.582096Z","shell.execute_reply":"2023-06-08T15:01:01.580600Z","shell.execute_reply.started":"2023-06-08T15:01:01.552893Z"},"trusted":true},"outputs":[],"source":["class ResNet20(nn.Module):\n","    \n","    def __init__(self, feature_channel, pooling_kernelsize = 3) -> None:\n","        super(ResNet20, self).__init__()       \n","        self.conv1 = nn.Sequential(\n","            nn.Conv1d(feature_channel, 16, 3, padding=1),\n","            nn.BatchNorm1d(16),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.ResBlocks = nn.Sequential(\n","            self.__ResBlock(16, 16),\n","            self.__ResBlock(16, 32),\n","            self.__ResBlock(32, 64),\n","        )\n","        self.poolkernelsize = pooling_kernelsize\n","    \n","    class ResidualBlock(nn.Module) :\n","    \n","        def __init__(self, in_channel, out_channel) -> None:\n","            super().__init__()\n","            self.seq =nn.Sequential(\n","                nn.Conv1d(in_channel, out_channel,3,padding=1),\n","                nn.BatchNorm1d(out_channel),\n","                nn.ReLU(inplace=True),\n","                nn.Conv1d(out_channel, out_channel, 3,padding=1),\n","                nn.BatchNorm1d(out_channel)\n","            )\n","            self.neck = nn.Sequential()\n","            if in_channel != out_channel:\n","                self.neck = nn.Sequential(\n","                    nn.Conv1d(in_channel, out_channel,3,padding=1),\n","                    nn.BatchNorm1d(out_channel)\n","                )\n","        \n","        def forward(self, x)->torch.Tensor:\n","            return F.relu(self.seq(x) + self.neck(x))\n","\n","    def __ResBlock(self,cin, cout):\n","        clist = [(cin, cout), (cout, cout), (cout, cout)]\n","        return nn.Sequential(\n","            *list(self.ResidualBlock(ci, co) for ci, co in clist)\n","        )\n","    \n","    def forward(self, x)->torch.Tensor :\n","        x1 = self.conv1(x.permute(0,2,1))\n","        x1 = self.ResBlocks(x1)\n","        x1 = x1.permute(0,2,1)\n","        if self.poolkernelsize > 1:\n","            x1 = F.avg_pool1d(x1, kernel_size=self.poolkernelsize)\n","        return x1.reshape(x1.shape[0], -1) #flatten\n","\n","\n","class ResConvClassifier(nn.Module):\n","    def __init__(\n","            self, feature_channels, seqlen, out_features, \n","            classifier_layers=[128], resnet_pooling_kernelsize = 1\n","        ) -> None:\n","        \n","        \"\"\"\n","        ResetNet20 output dimensions = floor(64/resnet_pooling_kernelsize)\n","        \n","        \"\"\"\n","        \n","        super(ResConvClassifier, self).__init__()\n","        self.emd = ResNet20(feature_channels,resnet_pooling_kernelsize)\n","        \n","        assert resnet_pooling_kernelsize > 0\n","        resnet_out = seqlen*int(math.floor(64.0/float(resnet_pooling_kernelsize)))\n","        \n","        layers = [resnet_out] + classifier_layers + [out_features]\n","        if (layers[1] > layers[0]):\n","            print(f\"Waring ! Resnet20 output are {layers[0]}\")\n","            print(f\"and you give {layers[1]}, try to lift dimension ????? \")\n","        if (layers[-1] > classifier_layers[-2]):\n","            print(f\"Waring ! output are {classifier_layers[-1]}\")\n","            print(f\"and you give {classifier_layers[-2]}, try to lift dimension ????? \")\n","        \n","        c = []\n","        j = -1\n","        for i in range(len(classifier_layers)):\n","            c.append(self.__LinBlock(layers[i],layers[i+1]))\n","            j = i\n","        c.append(nn.Linear(layers[j+1],layers[j+2]))\n","        self.classifier = nn.Sequential(*c)\n","\n","    def __LinBlock(self, ind, outd)->nn.Sequential:\n","        return nn.Sequential(\n","            nn.Linear(ind, outd),\n","            nn.BatchNorm1d(outd),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        x1 = self.emd(x)\n","        x1 = self.classifier(x1)\n","        return x1\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T15:01:06.117317Z","iopub.status.busy":"2023-06-08T15:01:06.116847Z","iopub.status.idle":"2023-06-08T15:01:06.205415Z","shell.execute_reply":"2023-06-08T15:01:06.204026Z","shell.execute_reply.started":"2023-06-08T15:01:06.117273Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of parameters in model - 405,443\n"]}],"source":["class Config:\n","    \n","    optimizer_name = \"Adam\"                       \n","    loss_function = \"BCEWithLogitsLoss\"           \n","    lr = 0.001                           \n","    num_epochs = 50                         \n","    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'         \n","    classifier_layers = [256,256,256]\n","    pooling_kernel = 3\n","    \n","cfg = Config()\n","    \n","\n","model = ResConvClassifier(\n","    feature_channels=len(datacfg.feature_list), \n","    seqlen=datacfg.window_size, \n","    out_features=len(datacfg.label_list), \n","    resnet_pooling_kernelsize = cfg.pooling_kernel,\n","    classifier_layers = cfg.classifier_layers\n",").to(cfg.device)\n","print(f\"Number of parameters in model - {count_parameters(model):,}\")\n","\n","optimizer = getattr(torch.optim, cfg.optimizer_name)(model.parameters(), lr=cfg.lr)\n","criterion = getattr(torch.nn, cfg.loss_function)(reduction='none').to(cfg.device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Training and Validation"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:45:23.731645Z","iopub.status.busy":"2023-06-08T10:45:23.730963Z","iopub.status.idle":"2023-06-08T10:55:35.187238Z","shell.execute_reply":"2023-06-08T10:55:35.185516Z","shell.execute_reply.started":"2023-06-08T10:45:23.731602Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4883/4883 [06:13<00:00, 13.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.1447\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4868/4868 [02:27<00:00, 32.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.0834, Validation Score: 0.259, ClassWise: 0.058,0.685,0.035\n","Saving Model ...\n","==================================================\n","Epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 1140/4883 [01:27<04:46, 13.04it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/573771834.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#sched.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3337376257.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, criterion, cfg)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                        \u001b[0;31m#根據loss做反向傳播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m                               \u001b[0;31m#優化器優化模型參數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    250\u001b[0m                  \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fused'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                  \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                  found_inf=found_inf)\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    314\u001b[0m          \u001b[0mdifferentiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdifferentiable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m          \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m          found_inf=found_inf)\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["loss_per_iter = []\n","valid_per_iter = []\n","max_score = 0.0\n","#sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.85)\n","for epoch in range(cfg.num_epochs):\n","    print(f\"Epoch: {epoch}\")\n","    loss = train_one_epoch(model, train_loader, optimizer, criterion,cfg)\n","    score = validation_one_epoch(model, valid_loader, criterion, cfg)\n","    #sched.step()\n","    loss_per_iter.append(loss)\n","    valid_per_iter.append(score)\n","    \n","    if score > max_score:\n","        max_score = score\n","        torch.save(model.state_dict(), \"best_model_state_b1.h5\")      #儲存最好的模型參數\n","        print(\"Saving Model ...\")\n","\n","    print(\"=\"*50)\n","    \n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-08T10:55:35.188986Z","iopub.status.idle":"2023-06-08T10:55:35.189822Z","shell.execute_reply":"2023-06-08T10:55:35.189562Z","shell.execute_reply.started":"2023-06-08T10:55:35.189533Z"},"trusted":true},"outputs":[],"source":["model =ResConvClassifier(\n","    feature_channels=len(datacfg.feature_list), \n","    seqlen=datacfg.window_size, \n","    out_features=len(datacfg.label_list), \n","    resnet_pooling_kernelsize = cfg.pooling_kernel,\n","    classifier_layers = cfg.classifier_layers\n",").to(cfg.device)\n","model.load_state_dict(torch.load(\"/kaggle/working/best_model_state_b1.h5\"))             #取得最好的模型參數\n","model.eval()\n","\n","test_defog_paths = glob.glob(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/*.csv\")\n","test_tdcsfog_paths = glob.glob(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/*.csv\")\n","test_fpaths = [(f, 'de') for f in test_defog_paths] + [(f, 'tdcs') for f in test_tdcsfog_paths]\n","\n","test_dataset = FOGDataset(test_fpaths, datacfg, split=\"test\")\n","test_loader = DataLoader(test_dataset, batch_size=datacfg.batch_size, num_workers=5)\n","\n","ids = []\n","preds = []\n","\n","for _id, x, _ in tqdm(test_loader):\n","    x = x.to(cfg.device).float()\n","    with torch.no_grad():\n","        y_pred = model(x)*0.1\n","    \n","    ids.extend(_id)\n","    preds.extend(list(np.nan_to_num(y_pred.cpu().numpy())))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-08T10:55:35.191345Z","iopub.status.idle":"2023-06-08T10:55:35.192154Z","shell.execute_reply":"2023-06-08T10:55:35.191907Z","shell.execute_reply.started":"2023-06-08T10:55:35.191879Z"},"trusted":true},"outputs":[],"source":["sample_submission = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv\")\n","sample_submission.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-08T10:55:35.193632Z","iopub.status.idle":"2023-06-08T10:55:35.194452Z","shell.execute_reply":"2023-06-08T10:55:35.194195Z","shell.execute_reply.started":"2023-06-08T10:55:35.194168Z"},"trusted":true},"outputs":[],"source":["preds = np.array(preds)\n","submission = pd.DataFrame(\n","    {\n","        'Id': ids, \n","        'StartHesitation': np.round(preds[:,0],5),                 \n","        'Turn': np.round(preds[:,1],5), \n","        'Walking': np.round(preds[:,2],5)\n","    }\n",")\n","\n","submission = pd.merge(sample_submission[['Id']], submission, how='left', on='Id').fillna(0.0)\n","submission.to_csv(\"submission.csv\", index=False)\n","print(submission.shape)\n","submission.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
